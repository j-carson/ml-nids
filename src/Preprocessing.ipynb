{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing \n",
    "\n",
    "This notebook focuses on ways to preprocess the full data set before using it for \n",
    "the various models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "from consistent_labels import get_attack_labels, get_common_services, get_common_protos, get_common_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy  1.15.4\n",
      "pandas 0.24.0\n",
      "sklearn 0.20.2\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -iv -p sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Connected: @nb15'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext sql\n",
    "%config SqlMagic.autopandas = True\n",
    "%sql postgres://localhost/nb15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This combines some collinear features\n",
    "def collinear_fix(X):\n",
    "    drop = ['sbytes', 'dbytes', 'state_FIN', 'stcpb', 'dtcpb', 'tcprtt']\n",
    "    X = X.drop(columns=drop)\n",
    "\n",
    "    X['avgspk'] = X.eval('(sloss+spkts)/2.')\n",
    "    X['avgdpk'] = X.eval('(dloss+dpkts)/2.')\n",
    "    X['avgwin'] = X.eval('(dwin+swin)/2.')\n",
    "    X['avg_port_ltm'] = X.eval('(ct_dst_sport_ltm+ct_src_dport_ltm)/2.')\n",
    "\n",
    "    drop = ['sloss', 'spkts', 'dloss', 'dpkts', 'dwin', 'swin', 'ct_dst_sport_ltm','ct_src_dport_ltm']\n",
    "    X = X.drop(columns=drop)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgres://localhost/nb15\n",
      "1524031 rows affected.\n",
      " * postgres://localhost/nb15\n",
      "1016013 rows affected.\n"
     ]
    }
   ],
   "source": [
    "raw_train = %sql select * from full_split where train_set = True;\n",
    "raw_test  = %sql select * from full_split where train_set = False;\n",
    "\n",
    "raw_train = raw_train.drop(columns=['train_set'])\n",
    "raw_test = raw_test.drop(columns=['train_set'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['label', 'attack_cat']\n",
    "X_train = raw_train.drop(columns=targets)\n",
    "Y_train = raw_train[targets]\n",
    "\n",
    "X_test = raw_test.drop(columns=targets)\n",
    "Y_test = raw_test[targets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop non-predictive columns\n",
    "\n",
    "We don't want our model to learn that attacks come to or from a specific host or at a specific time, or to \n",
    "predict based on the row number in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename = dict(index='id')\n",
    "non_predictors = ['id', 'srcip', 'dstip', 'sport', 'dsport', 'stime', 'ltime' ]\n",
    "X_train = X_train.rename(columns=rename).drop(columns=non_predictors)\n",
    "X_test  = X_test.rename(columns=rename).drop(columns=non_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['proto', 'state', 'dur', 'sbytes', 'dbytes', 'sttl', 'dttl', 'sloss',\n",
       "       'dloss', 'service', 'sload', 'dload', 'spkts', 'dpkts', 'swin', 'dwin',\n",
       "       'stcpb', 'dtcpb', 'smeansz', 'dmeansz', 'trans_depth', 'res_bdy_len',\n",
       "       'sjit', 'djit', 'sintpkt', 'dintpkt', 'tcprtt', 'synack', 'ackdat',\n",
       "       'is_sm_ips_ports', 'ct_state_ttl', 'ct_flw_http_mthd', 'is_ftp_login',\n",
       "       'ct_ftp_cmd', 'ct_srv_src', 'ct_srv_dst', 'ct_dst_ltm', 'ct_src_ltm',\n",
       "       'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "\n",
    "is_ftp_login was messed up in the MVP, so fix it here so it's 0/1 binary the way it's supposed to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'is_ftp_login > 1'\n",
    "X_train.loc[X_train.eval(query), 'is_ftp_login'] = 1\n",
    "X_test.loc[X_test.eval(query), 'is_ftp_login'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort columns by type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['proto', 'state', 'service']\n",
    "boolean = [ 'is_sm_ips_ports', 'is_ftp_login']\n",
    "numerical = list(X_train.columns)\n",
    "for col in categorical + boolean:\n",
    "    numerical.remove(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical columns one-hot encoding\n",
    "\n",
    "This section follows the same procedure used in the MVP notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writes a pandas.eval query string for <varname> not in <values>\n",
    "def make_other_query(varname, values):\n",
    "     return f\"{varname} != '\" + f\"' and {varname} != '\".join(values) + \"'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cats_train = X_train[categorical].copy(deep=True)\n",
    "new_cats_test = X_test[categorical].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tcp', 'udp', 'unas', 'arp', 'ospf']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_proto = get_common_protos()\n",
    "main_proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"proto != 'tcp' and proto != 'udp' and proto != 'unas' and proto != 'arp' and proto != 'ospf'\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proto_query = make_other_query('proto', main_proto)\n",
    "proto_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cats_train.loc[new_cats_train.eval(proto_query), 'proto'] = 'other'\n",
    "new_cats_test.loc[new_cats_test.eval(proto_query), 'proto'] = 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FIN', 'CON', 'INT', 'REQ']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_state = get_common_states()\n",
    "main_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_query = make_other_query('state', main_state)\n",
    "new_cats_train.loc[new_cats_train.eval(state_query), 'state'] = 'other'\n",
    "new_cats_test.loc[new_cats_test.eval(state_query), 'state'] = 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_service = get_common_services()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_query = make_other_query('service', main_service )\n",
    "new_cats_train.loc[new_cats_train.eval(service_query), 'service'] ='other'\n",
    "new_cats_test.loc[new_cats_test.eval(service_query), 'service'] ='other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cats_train.loc[new_cats_train.service == '-', 'service'] = 'none'\n",
    "new_cats_test.loc[new_cats_test.service == '-', 'service'] = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rather than 'drop_first', I'm going to drop the 'other' column for \n",
    "# later interpretability, except for proto_tcp which is too collinear\n",
    "# with the tcp stats and has to go.\n",
    "other_cols = [ 'proto_tcp', 'state_other', 'service_other' ]\n",
    "\n",
    "new_cats_train = pd.get_dummies(new_cats_train).drop(columns=other_cols)\n",
    "new_cats_test = pd.get_dummies(new_cats_test).drop(columns=other_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save one set with raw (but cleaned) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "XY_train = pd.concat([X_train[numerical], new_cats_train, X_train[boolean], Y_train],\n",
    "                     axis=1)\n",
    "XY_test = pd.concat([X_test[numerical], new_cats_test, X_test[boolean], Y_test],\n",
    "                   axis=1)\n",
    "\n",
    "XY_trainpk = Path('XY_trainun.pkl')\n",
    "XY_testpk = Path('XY_testun.pkl')\n",
    "\n",
    "with open(XY_trainpk, 'wb') as fp:\n",
    "    pickle.dump(XY_train, fp)\n",
    "with open(XY_testpk, 'wb') as fp:\n",
    "    pickle.dump(XY_test, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And save one set with the collinear fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "XY_train = collinear_fix(XY_train)\n",
    "XY_test = collinear_fix(XY_test)\n",
    "\n",
    "XY_trainpk = Path('XY_traincf.pkl')\n",
    "XY_testpk = Path('XY_testcf.pkl')\n",
    "\n",
    "with open(XY_trainpk, 'wb') as fp:\n",
    "    pickle.dump(XY_train, fp)\n",
    "with open(XY_testpk, 'wb') as fp:\n",
    "    pickle.dump(XY_test, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dur', 'sttl', 'dttl', 'sload', 'dload', 'smeansz', 'dmeansz',\n",
       "       'trans_depth', 'res_bdy_len', 'sjit', 'djit', 'sintpkt', 'dintpkt',\n",
       "       'synack', 'ackdat', 'ct_state_ttl', 'ct_flw_http_mthd', 'ct_ftp_cmd',\n",
       "       'ct_srv_src', 'ct_srv_dst', 'ct_dst_ltm', 'ct_src_ltm',\n",
       "       'ct_dst_src_ltm', 'proto_arp', 'proto_ospf', 'proto_other', 'proto_udp',\n",
       "       'proto_unas', 'state_CON', 'state_INT', 'state_REQ', 'is_sm_ips_ports',\n",
       "       'is_ftp_login', 'label', 'attack_cat', 'avgspk', 'avgdpk', 'avgwin',\n",
       "       'avg_port_ltm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XY_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
